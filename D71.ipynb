{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd068464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in /Users/haohuilu/anaconda3/lib/python3.11/site-packages (0.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34468727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "# Ignore all warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5026595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "glioma_grading_clinical_and_mutation_features = fetch_ucirepo(id=759) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = glioma_grading_clinical_and_mutation_features.data.features \n",
    "y = glioma_grading_clinical_and_mutation_features.data.targets \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78c224df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Race'] = np.where(X['Race'] == 'white', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "deb2f20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age_at_diagnosis</th>\n",
       "      <th>Race</th>\n",
       "      <th>IDH1</th>\n",
       "      <th>TP53</th>\n",
       "      <th>ATRX</th>\n",
       "      <th>PTEN</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>CIC</th>\n",
       "      <th>MUC16</th>\n",
       "      <th>...</th>\n",
       "      <th>FUBP1</th>\n",
       "      <th>RB1</th>\n",
       "      <th>NOTCH1</th>\n",
       "      <th>BCOR</th>\n",
       "      <th>CSMD3</th>\n",
       "      <th>SMARCA4</th>\n",
       "      <th>GRIN2A</th>\n",
       "      <th>IDH2</th>\n",
       "      <th>FAT4</th>\n",
       "      <th>PDGFRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>51.30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38.72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>35.17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>32.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>31.51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>1</td>\n",
       "      <td>77.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0</td>\n",
       "      <td>85.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>1</td>\n",
       "      <td>77.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>0</td>\n",
       "      <td>63.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>0</td>\n",
       "      <td>76.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>839 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Age_at_diagnosis  Race  IDH1  TP53  ATRX  PTEN  EGFR  CIC  MUC16  \\\n",
       "0         0             51.30     0     1     0     0     0     0    0      0   \n",
       "1         0             38.72     0     1     0     0     0     0    1      0   \n",
       "2         0             35.17     0     1     1     1     0     0    0      0   \n",
       "3         1             32.78     0     1     1     1     0     0    0      1   \n",
       "4         0             31.51     0     1     1     1     0     0    0      0   \n",
       "..      ...               ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
       "834       1             77.89     0     0     0     0     1     0    0      0   \n",
       "835       0             85.18     0     0     1     0     1     0    0      0   \n",
       "836       1             77.49     0     0     1     0     1     0    0      0   \n",
       "837       0             63.33     0     0     1     0     0     0    0      1   \n",
       "838       0             76.61     1     0     0     0     0     0    0      0   \n",
       "\n",
       "     ...  FUBP1  RB1  NOTCH1  BCOR  CSMD3  SMARCA4  GRIN2A  IDH2  FAT4  PDGFRA  \n",
       "0    ...      1    0       0     0      0        0       0     0     0       0  \n",
       "1    ...      0    0       0     0      0        0       0     0     0       0  \n",
       "2    ...      0    0       0     0      0        0       0     0     0       0  \n",
       "3    ...      0    0       0     0      0        0       0     0     1       0  \n",
       "4    ...      0    0       0     0      0        0       0     0     0       0  \n",
       "..   ...    ...  ...     ...   ...    ...      ...     ...   ...   ...     ...  \n",
       "834  ...      0    0       0     0      0        0       0     0     0       0  \n",
       "835  ...      0    0       0     0      0        0       0     0     0       0  \n",
       "836  ...      0    0       0     0      0        0       0     0     0       0  \n",
       "837  ...      0    1       0     0      0        0       0     0     0       0  \n",
       "838  ...      0    0       0     0      0        0       0     0     0       0  \n",
       "\n",
       "[839 rows x 23 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3c0c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks for race before scaling\n",
    "race_0_mask = X['Race'] == 0  \n",
    "race_1_mask = X['Race'] == 1  \n",
    "\n",
    "\n",
    "# Apply masks after scaling\n",
    "X_scaled_race_0 = X[race_0_mask].to_numpy()\n",
    "X_scaled_race_1 = X[race_1_mask].to_numpy()\n",
    "y_race_0 = y[race_0_mask].to_numpy()\n",
    "y_race_1 = y[race_1_mask].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba3b68da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  , 51.3 ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  , 38.72,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  , 35.17,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       ...,\n",
       "       [ 0.  , 85.18,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       [ 1.  , 77.49,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  , 63.33,  0.  , ...,  0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_race_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset from your local file system (replace 'path_to_file' with the actual file path)\n",
    "# dataset = pd.read_csv('path_to_file')\n",
    "\n",
    "# Preprocess the dataset\n",
    "# Convert categorical variables to numeric\n",
    "le = LabelEncoder()\n",
    "dataset['Race'] = dataset['Race'].map({'Female': 0, 'Male': 1})\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# Split the data into subgroups based on the protected feature (gender)\n",
    "group_male = dataset[dataset['Race'] == 1]  # Male\n",
    "group_female = dataset[dataset['Race'] == 0]  # Female\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'ANN': MLPClassifier(max_iter=1000)  # Increased max_iter for convergence\n",
    "}\n",
    "\n",
    "# K-fold cross-validation settings\n",
    "k = 20\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "\n",
    "# Prepare training and testing data\n",
    "X_train_male = group_male.drop(['diabetes'], axis=1)\n",
    "y_train_male = group_male['diabetes']\n",
    "X_test_all = dataset.drop(['diabetes'], axis=1)\n",
    "y_test_all = dataset['diabetes']\n",
    "X_test_female = group_female.drop(['diabetes'], axis=1)\n",
    "y_test_female = group_female['diabetes']\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X_train_male, y_train_male):\n",
    "        X_train, X_val = X_train_male.iloc[train_index], X_train_male.iloc[test_index]\n",
    "        y_train, y_val = y_train_male.iloc[train_index], y_train_male.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        predictions_all = model.predict(X_test_all)\n",
    "        predictions_female = model.predict(X_test_female)\n",
    "        \n",
    "        report_all = classification_report(y_test_all, predictions_all, output_dict=True)\n",
    "        report_female = classification_report(y_test_female, predictions_female, output_dict=True)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Fold': fold_idx,\n",
    "            'Accuracy_All': report_all['accuracy'],\n",
    "            'Precision_All': report_all['weighted avg']['precision'],\n",
    "            'Recall_All': report_all['weighted avg']['recall'],\n",
    "            'F1_Score_All': report_all['weighted avg']['f1-score'],\n",
    "            'Accuracy_Female': report_female['accuracy'],\n",
    "            'Precision_Female': report_female['weighted avg']['precision'],\n",
    "            'Recall_Female': report_female['weighted avg']['recall'],\n",
    "            'F1_Score_Female': report_female['weighted avg']['f1-score'],\n",
    "        })\n",
    "        fold_idx += 1\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.groupby(['Model']).mean())  # Displaying average metrics across folds for simplicity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "963b512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiments for race = 0 (white)\n",
      "Processing fold 1 for group 0 (white)\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 2 for group 0 (white)\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 3 for group 0 (white)\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 4 for group 0 (white)\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 5 for group 0 (white)\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 6 for group 0 (white)\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 7 for group 0 (white)\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 8 for group 0 (white)\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 9 for group 0 (white)\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 10 for group 0 (white)\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Starting experiments for race = 1 (other)\n",
      "Processing fold 1 for group 1\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 2 for group 1\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 3 for group 1\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 4 for group 1\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 5 for group 1\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 6 for group 1\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 7 for group 1\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 8 for group 1\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 9 for group 1\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Processing fold 10 for group 1\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "    Fold      Group   SVM_TPR   SVM_TNR   SVM_FPR   SVM_FNR  SVM_TP  SVM_TN  \\\n",
      "0      1  0 (white)  0.685714  0.952381  0.047619  0.314286      24      40   \n",
      "1      2  0 (white)  0.730769  0.862745  0.137255  0.269231      19      44   \n",
      "2      3  0 (white)  0.724138  0.687500  0.312500  0.275862      21      33   \n",
      "3      4  0 (white)  0.740741  0.780000  0.220000  0.259259      20      39   \n",
      "4      5  0 (white)  0.700000  0.851064  0.148936  0.300000      21      40   \n",
      "5      6  0 (white)  0.586207  0.829787  0.170213  0.413793      17      39   \n",
      "6      7  0 (white)  0.514286  0.853659  0.146341  0.485714      18      35   \n",
      "7      8  0 (white)  0.750000  0.840909  0.159091  0.250000      24      37   \n",
      "8      9  0 (white)  0.600000  0.853659  0.146341  0.400000      21      35   \n",
      "9     10  0 (white)  0.700000  0.673913  0.326087  0.300000      21      31   \n",
      "10     1          1  1.000000  0.000000  1.000000  0.000000       3       0   \n",
      "11     2          1  1.000000  0.000000  1.000000  0.000000       4       0   \n",
      "12     3          1  0.571429  0.000000  1.000000  0.428571       4       0   \n",
      "13     4          1  0.500000  1.000000  0.000000  0.500000       3       2   \n",
      "14     5          1  1.000000  0.000000  1.000000  0.000000       3       0   \n",
      "15     6          1  1.000000  0.000000  1.000000  0.000000       5       0   \n",
      "16     7          1  1.000000  0.000000  1.000000  0.000000       4       0   \n",
      "17     8          1  0.800000  0.000000  1.000000  0.200000       4       0   \n",
      "18     9          1  1.000000  0.000000  1.000000  0.000000       4       0   \n",
      "19    10          1  1.000000  0.000000  1.000000  0.000000       3       0   \n",
      "\n",
      "    SVM_FP  SVM_FN  ...  DT_FP  DT_FN   ANN_TPR   ANN_TNR   ANN_FPR   ANN_FNR  \\\n",
      "0        2      11  ...      8      9  0.857143  0.833333  0.166667  0.142857   \n",
      "1        7       7  ...      8      5  0.807692  0.921569  0.078431  0.192308   \n",
      "2       15       8  ...     14      5  0.965517  0.833333  0.166667  0.034483   \n",
      "3       11       7  ...      9      7  0.888889  0.780000  0.220000  0.111111   \n",
      "4        7       9  ...      6      4  0.966667  0.893617  0.106383  0.033333   \n",
      "5        8      12  ...      3      8  0.827586  0.978723  0.021277  0.172414   \n",
      "6        6      17  ...      5      6  0.942857  0.804878  0.195122  0.057143   \n",
      "7        7       8  ...      6      8  0.968750  0.818182  0.181818  0.031250   \n",
      "8        6      14  ...      5     11  0.914286  0.902439  0.097561  0.085714   \n",
      "9       15       9  ...      7      9  0.866667  0.869565  0.130435  0.133333   \n",
      "10       5       0  ...      4      0  1.000000  0.000000  1.000000  0.000000   \n",
      "11       4       0  ...      1      0  1.000000  0.000000  1.000000  0.000000   \n",
      "12       1       3  ...      1      1  1.000000  0.000000  1.000000  0.000000   \n",
      "13       0       3  ...      2      4  1.000000  0.000000  1.000000  0.000000   \n",
      "14       4       0  ...      1      0  1.000000  0.000000  1.000000  0.000000   \n",
      "15       2       0  ...      0      1  1.000000  0.000000  1.000000  0.000000   \n",
      "16       3       0  ...      0      2  1.000000  0.000000  1.000000  0.000000   \n",
      "17       2       1  ...      1      3  1.000000  0.000000  1.000000  0.000000   \n",
      "18       3       0  ...      2      2  1.000000  0.000000  1.000000  0.000000   \n",
      "19       4       0  ...      1      1  1.000000  0.000000  1.000000  0.000000   \n",
      "\n",
      "    ANN_TP  ANN_TN  ANN_FP  ANN_FN  \n",
      "0       30      35       7       5  \n",
      "1       21      47       4       5  \n",
      "2       28      40       8       1  \n",
      "3       24      39      11       3  \n",
      "4       29      42       5       1  \n",
      "5       24      46       1       5  \n",
      "6       33      33       8       2  \n",
      "7       31      36       8       1  \n",
      "8       32      37       4       3  \n",
      "9       26      40       6       4  \n",
      "10       3       0       5       0  \n",
      "11       4       0       4       0  \n",
      "12       7       0       1       0  \n",
      "13       6       0       2       0  \n",
      "14       3       0       4       0  \n",
      "15       5       0       2       0  \n",
      "16       4       0       3       0  \n",
      "17       5       0       2       0  \n",
      "18       4       0       3       0  \n",
      "19       3       0       4       0  \n",
      "\n",
      "[20 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    'SVM': SVC(random_state=seed),\n",
    "    'LR': LogisticRegression(random_state=seed),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'RF': RandomForestClassifier(random_state=seed),\n",
    "    'DT': DecisionTreeClassifier(random_state=seed),\n",
    "    'ANN': MLPClassifier(random_state=seed)\n",
    "}\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    TP = cm[1, 1]\n",
    "    TN = cm[0, 0]\n",
    "    FP = cm[0, 1]\n",
    "    FN = cm[1, 0]\n",
    "    \n",
    "    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0  # Sensitivity, recall, or true positive rate\n",
    "    TNR = TN / (TN + FP) if (TN + FP) > 0 else 0  # Specificity or true negative rate\n",
    "    FPR = FP / (FP + TN) if (FP + TN) > 0 else 0  # False positive rate\n",
    "    FNR = FN / (TP + FN) if (TP + FN) > 0 else 0  # False negative rate\n",
    "    \n",
    "    return TPR, TNR, FPR, FNR, TP, TN, FP, FN\n",
    "\n",
    "# Initialize a list to store temporary DataFrame objects\n",
    "results_list = []\n",
    "\n",
    "# Perform k-fold cross-validation and calculate sensitivity and specificity\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# Define function for running experiments and storing results\n",
    "def run_experiment(X_data, y_data, group_label, results_list):\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X_data)):\n",
    "        X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "        y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "        fold_results = {'Fold': fold + 1, 'Group': group_label}\n",
    "        print(f\"Processing fold {fold + 1} for group {group_label}\")\n",
    "\n",
    "        for name, model in models.items():\n",
    "            print(f\"   Training and evaluating model: {name}\")\n",
    "\n",
    "            # Fit the model\n",
    "            model.fit(X_train, y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "            # Calculate metrics\n",
    "            TPR, TNR, FPR, FNR, TP, TN, FP, FN = calculate_metrics(y_test, y_pred)\n",
    "            \n",
    "            # Store results in the fold_results dictionary\n",
    "            fold_results.update({\n",
    "                f'{name}_TPR': TPR, f'{name}_TNR': TNR,\n",
    "                f'{name}_FPR': FPR, f'{name}_FNR': FNR,\n",
    "                f'{name}_TP': TP, f'{name}_TN': TN,\n",
    "                f'{name}_FP': FP, f'{name}_FN': FN\n",
    "            })\n",
    "\n",
    "        # Append the dictionary to the results_list as a DataFrame\n",
    "        results_list.append(pd.DataFrame([fold_results]))\n",
    "\n",
    "# Running experiments for each race\n",
    "print(\"Starting experiments for race = 0 (white)\")\n",
    "run_experiment(X_scaled_race_0, y_race_0, '0 (white)', results_list)\n",
    "\n",
    "print(\"Starting experiments for race = 1 (other)\")\n",
    "run_experiment(X_scaled_race_1, y_race_1, '1', results_list)\n",
    "\n",
    "# Concatenate all DataFrames in the results_list into one DataFrame\n",
    "final_results_df = pd.concat(results_list, ignore_index=True)\n",
    "print(final_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7cbaed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat(results_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bec58e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = 'D71_results.xlsx'\n",
    "results_df.to_excel(results_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb4256dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./result/D71_results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa67c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Group</th>\n",
       "      <th>SVM_TPR</th>\n",
       "      <th>SVM_TNR</th>\n",
       "      <th>SVM_FPR</th>\n",
       "      <th>SVM_FNR</th>\n",
       "      <th>SVM_TP</th>\n",
       "      <th>SVM_TN</th>\n",
       "      <th>SVM_FP</th>\n",
       "      <th>SVM_FN</th>\n",
       "      <th>...</th>\n",
       "      <th>DT_FP</th>\n",
       "      <th>DT_FN</th>\n",
       "      <th>ANN_TPR</th>\n",
       "      <th>ANN_TNR</th>\n",
       "      <th>ANN_FPR</th>\n",
       "      <th>ANN_FNR</th>\n",
       "      <th>ANN_TP</th>\n",
       "      <th>ANN_TN</th>\n",
       "      <th>ANN_FP</th>\n",
       "      <th>ANN_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0 (white)</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0 (white)</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>21</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0 (white)</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0 (white)</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0 (white)</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold      Group   SVM_TPR   SVM_TNR   SVM_FPR   SVM_FNR  SVM_TP  SVM_TN  \\\n",
       "0     1  0 (white)  0.685714  0.952381  0.047619  0.314286      24      40   \n",
       "1     2  0 (white)  0.730769  0.862745  0.137255  0.269231      19      44   \n",
       "2     3  0 (white)  0.724138  0.687500  0.312500  0.275862      21      33   \n",
       "3     4  0 (white)  0.740741  0.780000  0.220000  0.259259      20      39   \n",
       "4     5  0 (white)  0.700000  0.851064  0.148936  0.300000      21      40   \n",
       "\n",
       "   SVM_FP  SVM_FN  ...  DT_FP  DT_FN   ANN_TPR   ANN_TNR   ANN_FPR   ANN_FNR  \\\n",
       "0       2      11  ...      8      9  0.857143  0.833333  0.166667  0.142857   \n",
       "1       7       7  ...      8      5  0.807692  0.921569  0.078431  0.192308   \n",
       "2      15       8  ...     14      5  0.965517  0.833333  0.166667  0.034483   \n",
       "3      11       7  ...      9      7  0.888889  0.780000  0.220000  0.111111   \n",
       "4       7       9  ...      6      4  0.966667  0.893617  0.106383  0.033333   \n",
       "\n",
       "   ANN_TP  ANN_TN  ANN_FP  ANN_FN  \n",
       "0      30      35       7       5  \n",
       "1      21      47       4       5  \n",
       "2      28      40       8       1  \n",
       "3      24      39      11       3  \n",
       "4      29      42       5       1  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "316cc723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def perform_t_tests(df, algorithm):\n",
    "    # Define the column names based on the algorithm\n",
    "    tpr_col = f\"{algorithm}_TPR\"\n",
    "    fpr_col = f\"{algorithm}_FPR\"\n",
    "    fn_col = f\"{algorithm}_FN\"\n",
    "    fp_col = f\"{algorithm}_FP\"\n",
    "    \n",
    "    # Define the groups\n",
    "    protected_group = df['Group'] == '0 (white)'\n",
    "    unprotected_group = ~protected_group\n",
    "\n",
    "    # Extract the metrics\n",
    "    protected_tpr = df.loc[protected_group, tpr_col].values\n",
    "    unprotected_tpr = df.loc[unprotected_group, tpr_col].values\n",
    "\n",
    "    protected_fpr = df.loc[protected_group, fpr_col].values\n",
    "    unprotected_fpr = df.loc[unprotected_group, fpr_col].values\n",
    "\n",
    "    protected_ratio_fn_fp = (df.loc[protected_group, fn_col] / df.loc[protected_group, fp_col]).values\n",
    "    unprotected_ratio_fn_fp = (df.loc[unprotected_group, fn_col] / df.loc[unprotected_group, fp_col]).values\n",
    "\n",
    "    # Perform t-tests\n",
    "\n",
    "    # Definition 1: Equalised Odds (TPR and FPR)\n",
    "    tpr_ttest = ttest_ind(protected_tpr, unprotected_tpr)\n",
    "    fpr_ttest = ttest_ind(protected_fpr, unprotected_fpr)\n",
    "\n",
    "    # Definition 2: Equal Opportunity (TPR)\n",
    "    equal_opportunity_ttest = ttest_ind(protected_tpr, unprotected_tpr)\n",
    "\n",
    "    # Definition 3: Treatment Equality (Ratio of false negatives to false positives)\n",
    "    treatment_equality_ttest = ttest_ind(protected_ratio_fn_fp, unprotected_ratio_fn_fp)\n",
    "\n",
    "    # Definition 4: Aggregate of all conditions\n",
    "    aggregate_tpr_ttest = ttest_ind(protected_tpr, unprotected_tpr)\n",
    "    aggregate_fpr_ttest = ttest_ind(protected_fpr, unprotected_fpr)\n",
    "    aggregate_ratio_ttest = ttest_ind(protected_ratio_fn_fp, unprotected_ratio_fn_fp)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"{algorithm} - Equalised Odds (TPR):\", tpr_ttest)\n",
    "    print(f\"{algorithm} - Equalised Odds (FPR):\", fpr_ttest)\n",
    "    print(f\"{algorithm} - Equal Opportunity (TPR):\", equal_opportunity_ttest)\n",
    "    print(f\"{algorithm} - Aggregate - TPR:\", aggregate_tpr_ttest)\n",
    "    print(f\"{algorithm} - Aggregate - FPR:\", aggregate_fpr_ttest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1eaef293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Equalised Odds (TPR): TtestResult(statistic=-3.1995853449641456, pvalue=0.0049670154933958415, df=18.0)\n",
      "SVM - Equalised Odds (FPR): TtestResult(statistic=-6.944461281636296, pvalue=1.7281481730698042e-06, df=18.0)\n",
      "SVM - Equal Opportunity (TPR): TtestResult(statistic=-3.1995853449641456, pvalue=0.0049670154933958415, df=18.0)\n",
      "SVM - Aggregate - TPR: TtestResult(statistic=-3.1995853449641456, pvalue=0.0049670154933958415, df=18.0)\n",
      "SVM - Aggregate - FPR: TtestResult(statistic=-6.944461281636296, pvalue=1.7281481730698042e-06, df=18.0)\n",
      "LR - Equalised Odds (TPR): TtestResult(statistic=1.2194268267704633, pvalue=0.2384209011519161, df=18.0)\n",
      "LR - Equalised Odds (FPR): TtestResult(statistic=-3.6518590160813544, pvalue=0.0018240704312290203, df=18.0)\n",
      "LR - Equal Opportunity (TPR): TtestResult(statistic=1.2194268267704633, pvalue=0.2384209011519161, df=18.0)\n",
      "LR - Aggregate - TPR: TtestResult(statistic=1.2194268267704633, pvalue=0.2384209011519161, df=18.0)\n",
      "LR - Aggregate - FPR: TtestResult(statistic=-3.6518590160813544, pvalue=0.0018240704312290203, df=18.0)\n",
      "DT - Equalised Odds (TPR): TtestResult(statistic=0.7294897061846375, pvalue=0.47508872997674734, df=18.0)\n",
      "DT - Equalised Odds (FPR): TtestResult(statistic=-2.611332344805092, pvalue=0.017673003594620266, df=18.0)\n",
      "DT - Equal Opportunity (TPR): TtestResult(statistic=0.7294897061846375, pvalue=0.47508872997674734, df=18.0)\n",
      "DT - Aggregate - TPR: TtestResult(statistic=0.7294897061846375, pvalue=0.47508872997674734, df=18.0)\n",
      "DT - Aggregate - FPR: TtestResult(statistic=-2.611332344805092, pvalue=0.017673003594620266, df=18.0)\n",
      "RF - Equalised Odds (TPR): TtestResult(statistic=-0.43950032314964477, pvalue=0.6655300763810013, df=18.0)\n",
      "RF - Equalised Odds (FPR): TtestResult(statistic=-3.481338082326297, pvalue=0.002664871058316407, df=18.0)\n",
      "RF - Equal Opportunity (TPR): TtestResult(statistic=-0.43950032314964477, pvalue=0.6655300763810013, df=18.0)\n",
      "RF - Aggregate - TPR: TtestResult(statistic=-0.43950032314964477, pvalue=0.6655300763810013, df=18.0)\n",
      "RF - Aggregate - FPR: TtestResult(statistic=-3.481338082326297, pvalue=0.002664871058316407, df=18.0)\n",
      "ANN - Equalised Odds (TPR): TtestResult(statistic=-5.2437030897188155, pvalue=5.495250965191935e-05, df=18.0)\n",
      "ANN - Equalised Odds (FPR): TtestResult(statistic=-44.83333457557132, pvalue=6.365080885010628e-20, df=18.0)\n",
      "ANN - Equal Opportunity (TPR): TtestResult(statistic=-5.2437030897188155, pvalue=5.495250965191935e-05, df=18.0)\n",
      "ANN - Aggregate - TPR: TtestResult(statistic=-5.2437030897188155, pvalue=5.495250965191935e-05, df=18.0)\n",
      "ANN - Aggregate - FPR: TtestResult(statistic=-44.83333457557132, pvalue=6.365080885010628e-20, df=18.0)\n"
     ]
    }
   ],
   "source": [
    "perform_t_tests(df, 'SVM')\n",
    "perform_t_tests(df, 'LR')\n",
    "perform_t_tests(df, 'DT')\n",
    "perform_t_tests(df, 'RF')\n",
    "perform_t_tests(df, 'ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0783fe63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
