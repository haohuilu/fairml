{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa6ddc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "\n",
    "# Ignore all warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('./data/diabetes_prediction_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3f033fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "smoking_history        0\n",
      "bmi                    0\n",
      "HbA1c_level            0\n",
      "blood_glucose_level    0\n",
      "diabetes               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset.head()\n",
    "print(dataset.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f0c3565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for the entire dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     91500\n",
      "           1       0.79      0.87      0.83      8500\n",
      "\n",
      "    accuracy                           0.97    100000\n",
      "   macro avg       0.89      0.92      0.91    100000\n",
      "weighted avg       0.97      0.97      0.97    100000\n",
      "\n",
      "Performance on 'female' group:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97     54091\n",
      "           1       0.64      0.75      0.69      4461\n",
      "\n",
      "    accuracy                           0.95     58552\n",
      "   macro avg       0.81      0.86      0.83     58552\n",
      "weighted avg       0.95      0.95      0.95     58552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset from your local file system (replace 'path_to_file' with the actual file path)\n",
    "\n",
    "# Preprocess the dataset\n",
    "# Convert categorical variables to numeric\n",
    "le = LabelEncoder()\n",
    "dataset['smoking_history'] = le.fit_transform(dataset['smoking_history'])\n",
    "dataset['gender'] = dataset['gender'].map({'Female': 0, 'Male': 1})\n",
    "dataset =  dataset.dropna()\n",
    "# Split the data into subgroups based on the protected feature (gender)\n",
    "group_male = dataset[dataset['gender'] == 1]  # Male\n",
    "group_female = dataset[dataset['gender'] == 0]  # Female\n",
    "\n",
    "# Train a model on one subgroup (e.g., 'male')\n",
    "X_train = group_male.drop(['diabetes'], axis=1)\n",
    "y_train = group_male['diabetes']\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the entire dataset\n",
    "X_test = dataset.drop(['diabetes'], axis=1)\n",
    "y_test = dataset['diabetes']\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Classification report for the entire dataset:\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# You might want to look at performance specifically on the 'female' group\n",
    "X_test_female = group_female.drop(['diabetes'], axis=1)\n",
    "y_test_female = group_female['diabetes']\n",
    "predictions_female = model.predict(X_test_female)\n",
    "print(\"Performance on 'female' group:\")\n",
    "print(classification_report(y_test_female, predictions_female))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3491fba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Fold  Accuracy_All  Precision_All  Recall_All  \\\n",
      "Model                                                                \n",
      "ANN                  10.5      0.472499       0.893893    0.472499   \n",
      "Decision Tree        10.5      0.968879       0.970291    0.968879   \n",
      "KNN                  10.5      0.955017       0.951920    0.955017   \n",
      "Logistic Regression  10.5      0.441569       0.889843    0.441569   \n",
      "Random Forest        10.5      0.982950       0.982731    0.982950   \n",
      "SVM                  10.5      0.946020       0.949008    0.946020   \n",
      "\n",
      "                     F1_Score_All  Accuracy_Female  Precision_Female  \\\n",
      "Model                                                                  \n",
      "ANN                      0.570299         0.129552          0.929944   \n",
      "Decision Tree            0.969453         0.949306          0.953584   \n",
      "KNN                      0.950950         0.954025          0.949867   \n",
      "Logistic Regression      0.539333         0.078794          0.929631   \n",
      "Random Forest            0.982353         0.972664          0.971777   \n",
      "SVM                      0.934245         0.952130          0.954488   \n",
      "\n",
      "                     Recall_Female  F1_Score_Female  \n",
      "Model                                                \n",
      "ANN                       0.129552         0.111994  \n",
      "Decision Tree             0.949306         0.951085  \n",
      "KNN                       0.954025         0.950070  \n",
      "Logistic Regression       0.078794         0.016010  \n",
      "Random Forest             0.972664         0.970827  \n",
      "SVM                       0.952130         0.941770  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset from your local file system (replace 'path_to_file' with the actual file path)\n",
    "# dataset = pd.read_csv('path_to_file')\n",
    "\n",
    "# Preprocess the dataset\n",
    "# Convert categorical variables to numeric\n",
    "le = LabelEncoder()\n",
    "dataset['smoking_history'] = le.fit_transform(dataset['smoking_history'])\n",
    "dataset['gender'] = dataset['gender'].map({'Female': 0, 'Male': 1})\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# Split the data into subgroups based on the protected feature (gender)\n",
    "group_male = dataset[dataset['gender'] == 1]  # Male\n",
    "group_female = dataset[dataset['gender'] == 0]  # Female\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'ANN': MLPClassifier(max_iter=1000)  # Increased max_iter for convergence\n",
    "}\n",
    "\n",
    "# K-fold cross-validation settings\n",
    "k = 20\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "\n",
    "# Prepare training and testing data\n",
    "X_train_male = group_male.drop(['diabetes'], axis=1)\n",
    "y_train_male = group_male['diabetes']\n",
    "X_test_all = dataset.drop(['diabetes'], axis=1)\n",
    "y_test_all = dataset['diabetes']\n",
    "X_test_female = group_female.drop(['diabetes'], axis=1)\n",
    "y_test_female = group_female['diabetes']\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X_train_male, y_train_male):\n",
    "        X_train, X_val = X_train_male.iloc[train_index], X_train_male.iloc[test_index]\n",
    "        y_train, y_val = y_train_male.iloc[train_index], y_train_male.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        predictions_all = model.predict(X_test_all)\n",
    "        predictions_female = model.predict(X_test_female)\n",
    "        \n",
    "        report_all = classification_report(y_test_all, predictions_all, output_dict=True)\n",
    "        report_female = classification_report(y_test_female, predictions_female, output_dict=True)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Fold': fold_idx,\n",
    "            'Accuracy_All': report_all['accuracy'],\n",
    "            'Precision_All': report_all['weighted avg']['precision'],\n",
    "            'Recall_All': report_all['weighted avg']['recall'],\n",
    "            'F1_Score_All': report_all['weighted avg']['f1-score'],\n",
    "            'Accuracy_Female': report_female['accuracy'],\n",
    "            'Precision_Female': report_female['weighted avg']['precision'],\n",
    "            'Recall_Female': report_female['weighted avg']['recall'],\n",
    "            'F1_Score_Female': report_female['weighted avg']['f1-score'],\n",
    "        })\n",
    "        fold_idx += 1\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.groupby(['Model']).mean())  # Displaying average metrics across folds for simplicity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "215f4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('D95_model_evaluation_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42143eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573065ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247193e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['gender'] = dataset['gender'].map({'Female': 0, 'Male': 1})\n",
    "dataset = pd.get_dummies(dataset, columns=['smoking_history'])\n",
    "dataset = dataset.dropna()\n",
    "dataset.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f353e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gender_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e5b48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiments for Gender = Female (0)\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "Starting experiments for Gender = Male (1)\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "   Training and evaluating model: SVM\n",
      "   Training and evaluating model: LR\n",
      "   Training and evaluating model: KNN\n",
      "   Training and evaluating model: RF\n",
      "   Training and evaluating model: DT\n",
      "   Training and evaluating model: ANN\n",
      "    Fold   Group   SVM_TPR   SVM_TNR   SVM_FPR   SVM_FNR  SVM_TP  SVM_TN  \\\n",
      "0      1  Female  0.582938  0.998896  0.001104  0.417062     123    2714   \n",
      "1      2  Female  0.572052  0.999259  0.000741  0.427948     131    2697   \n",
      "2      3  Female  0.576190  0.998160  0.001840  0.423810     121    2713   \n",
      "3      4  Female  0.558685  0.999632  0.000368  0.441315     119    2714   \n",
      "4      5  Female  0.549107  0.999260  0.000740  0.450893     123    2702   \n",
      "5      6  Female  0.566964  0.998151  0.001849  0.433036     127    2699   \n",
      "6      7  Female  0.607143  0.999260  0.000740  0.392857     136    2702   \n",
      "7      8  Female  0.600877  0.998889  0.001111  0.399123     137    2697   \n",
      "8      9  Female  0.575342  0.998893  0.001107  0.424658     126    2706   \n",
      "9     10  Female  0.613333  0.999630  0.000370  0.386667     138    2702   \n",
      "10    11  Female  0.657658  0.999261  0.000739  0.342342     146    2704   \n",
      "11    12  Female  0.526786  0.998521  0.001479  0.473214     118    2700   \n",
      "12    13  Female  0.518672  0.999255  0.000745  0.481328     125    2684   \n",
      "13    14  Female  0.512821  0.998143  0.001857  0.487179     120    2688   \n",
      "14    15  Female  0.521531  0.998528  0.001472  0.478469     109    2714   \n",
      "15    16  Female  0.595455  0.998522  0.001478  0.404545     131    2703   \n",
      "16    17  Female  0.587983  0.999258  0.000742  0.412017     137    2692   \n",
      "17    18  Female  0.566116  0.999628  0.000372  0.433884     137    2684   \n",
      "18    19  Female  0.618357  0.998897  0.001103  0.381643     128    2717   \n",
      "19    20  Female  0.563063  0.998891  0.001109  0.436937     125    2702   \n",
      "20     1    Male  0.600000  0.997869  0.002131  0.400000     117    1873   \n",
      "21     2    Male  0.585714  0.998926  0.001074  0.414286     123    1860   \n",
      "22     3    Male  0.575269  0.998940  0.001060  0.424731     107    1884   \n",
      "23     4    Male  0.601266  0.997910  0.002090  0.398734      95    1910   \n",
      "24     5    Male  0.582569  0.998921  0.001079  0.417431     127    1852   \n",
      "25     6    Male  0.559783  0.997881  0.002119  0.440217     103    1884   \n",
      "26     7    Male  0.526882  0.999470  0.000530  0.473118      98    1885   \n",
      "27     8    Male  0.572816  0.997856  0.002144  0.427184     118    1862   \n",
      "28     9    Male  0.539535  0.997307  0.002693  0.460465     116    1852   \n",
      "29    10    Male  0.643836  0.997841  0.002159  0.356164     141    1849   \n",
      "30    11    Male  0.622449  0.997867  0.002133  0.377551     122    1871   \n",
      "31    12    Male  0.558824  0.997322  0.002678  0.441176     114    1862   \n",
      "32    13    Male  0.570136  0.997297  0.002703  0.429864     126    1845   \n",
      "33    14    Male  0.619289  0.997332  0.002668  0.380711     122    1869   \n",
      "34    15    Male  0.568807  0.997841  0.002159  0.431193     124    1849   \n",
      "35    16    Male  0.574359  0.997335  0.002665  0.425641     112    1871   \n",
      "36    17    Male  0.514563  0.997855  0.002145  0.485437     106    1861   \n",
      "37    18    Male  0.560976  0.997856  0.002144  0.439024     115    1862   \n",
      "38    19    Male  0.575000  0.997328  0.002672  0.425000     115    1866   \n",
      "39    20    Male  0.527273  0.998379  0.001621  0.472727     116    1848   \n",
      "\n",
      "    SVM_FP  SVM_FN  ...  DT_FP  DT_FN   ANN_TPR   ANN_TNR   ANN_FPR   ANN_FNR  \\\n",
      "0        3      88  ...     96     51  0.739336  0.997056  0.002944  0.260664   \n",
      "1        2      98  ...     70     57  0.698690  0.998888  0.001112  0.301310   \n",
      "2        5      89  ...     69     54  0.666667  0.998896  0.001104  0.333333   \n",
      "3        1      94  ...     59     56  0.676056  0.999632  0.000368  0.323944   \n",
      "4        2     101  ...     70     59  0.683036  0.998521  0.001479  0.316964   \n",
      "5        5      97  ...     50     52  0.696429  0.997781  0.002219  0.303571   \n",
      "6        2      88  ...     72     58  0.696429  0.999260  0.000740  0.303571   \n",
      "7        3      91  ...     54     50  0.736842  0.998889  0.001111  0.263158   \n",
      "8        3      93  ...     56     59  0.694064  0.997785  0.002215  0.305936   \n",
      "9        1      87  ...     55     51  0.737778  0.998890  0.001110  0.262222   \n",
      "10       2      76  ...     69     58  0.702703  0.996674  0.003326  0.297297   \n",
      "11       4     106  ...     68     67  0.651786  0.998151  0.001849  0.348214   \n",
      "12       2     116  ...     78     70  0.680498  0.998511  0.001489  0.319502   \n",
      "13       5     114  ...     82     72  0.641026  0.998886  0.001114  0.358974   \n",
      "14       4     100  ...     79     56  0.645933  0.998160  0.001840  0.354067   \n",
      "15       4      89  ...     66     53  0.713636  0.998522  0.001478  0.286364   \n",
      "16       2      96  ...     74     55  0.682403  0.999258  0.000742  0.317597   \n",
      "17       1     105  ...     68     63  0.685950  0.997765  0.002235  0.314050   \n",
      "18       3      79  ...     69     55  0.695652  0.998897  0.001103  0.304348   \n",
      "19       3      97  ...     68     64  0.657658  0.997782  0.002218  0.342342   \n",
      "20       4      78  ...     58     45  0.682051  0.999467  0.000533  0.317949   \n",
      "21       2      87  ...     64     53  0.704762  0.997315  0.002685  0.295238   \n",
      "22       2      79  ...     58     48  0.693548  0.997349  0.002651  0.306452   \n",
      "23       4      63  ...     60     36  0.708861  0.998955  0.001045  0.291139   \n",
      "24       2      91  ...     58     55  0.674312  0.998382  0.001618  0.325688   \n",
      "25       4      81  ...     67     46  0.684783  0.996822  0.003178  0.315217   \n",
      "26       1      88  ...     61     53  0.634409  0.999470  0.000530  0.365591   \n",
      "27       4      88  ...     51     52  0.718447  0.996785  0.003215  0.281553   \n",
      "28       5      99  ...     53     51  0.665116  0.998384  0.001616  0.334884   \n",
      "29       4      78  ...     64     41  0.744292  0.998921  0.001079  0.255708   \n",
      "30       4      74  ...     49     44  0.734694  0.998400  0.001600  0.265306   \n",
      "31       5      90  ...     58     52  0.656863  0.997858  0.002142  0.343137   \n",
      "32       5      95  ...     68     59  0.678733  0.991892  0.008108  0.321267   \n",
      "33       5      75  ...     60     45  0.736041  0.996265  0.003735  0.263959   \n",
      "34       4      94  ...     61     62  0.665138  0.998381  0.001619  0.334862   \n",
      "35       5      83  ...     60     57  0.651282  0.997868  0.002132  0.348718   \n",
      "36       4     100  ...     62     61  0.645631  1.000000  0.000000  0.354369   \n",
      "37       4      90  ...     64     53  0.643902  0.997856  0.002144  0.356098   \n",
      "38       5      85  ...     68     56  0.675000  0.998397  0.001603  0.325000   \n",
      "39       3     104  ...     47     71  0.650000  0.996218  0.003782  0.350000   \n",
      "\n",
      "    ANN_TP  ANN_TN  ANN_FP  ANN_FN  \n",
      "0      156    2709       8      55  \n",
      "1      160    2696       3      69  \n",
      "2      140    2715       3      70  \n",
      "3      144    2714       1      69  \n",
      "4      153    2700       4      71  \n",
      "5      156    2698       6      68  \n",
      "6      156    2702       2      68  \n",
      "7      168    2697       3      60  \n",
      "8      152    2703       6      67  \n",
      "9      166    2700       3      59  \n",
      "10     156    2697       9      66  \n",
      "11     146    2699       5      78  \n",
      "12     164    2682       4      77  \n",
      "13     150    2690       3      84  \n",
      "14     135    2713       5      74  \n",
      "15     157    2703       4      63  \n",
      "16     159    2692       2      74  \n",
      "17     166    2679       6      76  \n",
      "18     144    2717       3      63  \n",
      "19     146    2699       6      76  \n",
      "20     133    1876       1      62  \n",
      "21     148    1857       5      62  \n",
      "22     129    1881       5      57  \n",
      "23     112    1912       2      46  \n",
      "24     147    1851       3      71  \n",
      "25     126    1882       6      58  \n",
      "26     118    1885       1      68  \n",
      "27     148    1860       6      58  \n",
      "28     143    1854       3      72  \n",
      "29     163    1851       2      56  \n",
      "30     144    1872       3      52  \n",
      "31     134    1863       4      70  \n",
      "32     150    1835      15      71  \n",
      "33     145    1867       7      52  \n",
      "34     145    1850       3      73  \n",
      "35     127    1872       4      68  \n",
      "36     133    1865       0      73  \n",
      "37     132    1862       4      73  \n",
      "38     135    1868       3      65  \n",
      "39     143    1844       7      77  \n",
      "\n",
      "[40 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define your features and label, but keep 'gender' for creating the mask\n",
    "X = dataset.drop('diabetes', axis=1)\n",
    "y = dataset['diabetes'].values\n",
    "\n",
    "# Create masks for gender before scaling\n",
    "gender_0_mask = dataset['gender'] == 0  # Assuming '0' represents Female\n",
    "gender_1_mask = dataset['gender'] == 1  # Assuming '1' represents Male\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply masks after scaling\n",
    "X_scaled_gender_0 = X_scaled[gender_0_mask]\n",
    "X_scaled_gender_1 = X_scaled[gender_1_mask]\n",
    "y_gender_0 = y[gender_0_mask]\n",
    "y_gender_1 = y[gender_1_mask]\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'SVM': SVC(random_state=seed),\n",
    "    'LR': LogisticRegression(random_state=seed),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'RF': RandomForestClassifier(random_state=seed),\n",
    "    'DT': DecisionTreeClassifier(random_state=seed),\n",
    "    'ANN': MLPClassifier(random_state=seed)\n",
    "}\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    TP = cm[1, 1]\n",
    "    TN = cm[0, 0]\n",
    "    FP = cm[0, 1]\n",
    "    FN = cm[1, 0]\n",
    "    \n",
    "    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0  # Sensitivity, recall, or true positive rate\n",
    "    TNR = TN / (TN + FP) if (TN + FP) > 0 else 0  # Specificity or true negative rate\n",
    "    FPR = FP / (FP + TN) if (FP + TN) > 0 else 0  # False positive rate\n",
    "    FNR = FN / (TP + FN) if (TP + FN) > 0 else 0  # False negative rate\n",
    "    \n",
    "    return TPR, TNR, FPR, FNR, TP, TN, FP, FN\n",
    "\n",
    "# Initialize a list to store temporary DataFrame objects\n",
    "results_list = []\n",
    "\n",
    "# Perform k-fold cross-validation and calculate sensitivity and specificity\n",
    "kf = KFold(n_splits=20, shuffle=True, random_state=seed)\n",
    "\n",
    "# Define function for running experiments and storing results\n",
    "def run_experiment(X_data, y_data, group_label, results_list):\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X_data)):\n",
    "        X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "        y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "        fold_results = {'Fold': fold + 1, 'Group': group_label}\n",
    "        print(f\"Processing fold {fold + 1} for group {group_label}\")\n",
    "\n",
    "        for name, model in models.items():\n",
    "            print(f\"   Training and evaluating model: {name}\")\n",
    "\n",
    "            # Fit the model\n",
    "            model.fit(X_train, y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "            # Calculate metrics\n",
    "            TPR, TNR, FPR, FNR, TP, TN, FP, FN = calculate_metrics(y_test, y_pred)\n",
    "            \n",
    "            # Store results in the fold_results dictionary\n",
    "            fold_results.update({\n",
    "                f'{name}_TPR': TPR, f'{name}_TNR': TNR,\n",
    "                f'{name}_FPR': FPR, f'{name}_FNR': FNR,\n",
    "                f'{name}_TP': TP, f'{name}_TN': TN,\n",
    "                f'{name}_FP': FP, f'{name}_FN': FN\n",
    "            })\n",
    "\n",
    "        # Append the dictionary to the results_list as a DataFrame\n",
    "        results_list.append(pd.DataFrame([fold_results]))\n",
    "\n",
    "# Running experiments for each gender\n",
    "print(\"Starting experiments for Gender = Female (0)\")\n",
    "run_experiment(X_scaled_gender_0, y_gender_0, 'Female', results_list)\n",
    "\n",
    "print(\"Starting experiments for Gender = Male (1)\")\n",
    "run_experiment(X_scaled_gender_1, y_gender_1, 'Male', results_list)\n",
    "\n",
    "# Concatenate all DataFrames in the results_list into one DataFrame\n",
    "final_results_df = pd.concat(results_list, ignore_index=True)\n",
    "print(final_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eabb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat(results_list, ignore_index=True)\n",
    "results_path = 'D95_results.xlsx'\n",
    "results_df.to_excel(results_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df['gender'] = protected_feature\n",
    "df['target'] = y\n",
    "\n",
    "# Split the data into subgroups based on the protected feature\n",
    "group_male = df[df['gender'] == 0]\n",
    "group_female = df[df['gender'] == 1]\n",
    "\n",
    "# Train a model on one subgroup (e.g., 'male')\n",
    "X_train, y_train = group_male.drop(['target', 'gender'], axis=1), group_male['target']\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the entire dataset\n",
    "X_test, y_test = df.drop(['target', 'gender'], axis=1), df['target']\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# You might want to look at performance specifically on the 'female' group\n",
    "X_test_female, y_test_female = group_female.drop(['target', 'gender'], axis=1), group_female['target']\n",
    "predictions_female = model.predict(X_test_female)\n",
    "print(\"Performance on 'female' group:\")\n",
    "print(classification_report(y_test_female, predictions_female))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a36ceae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./result/D95_results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2790442b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Group</th>\n",
       "      <th>SVM_TPR</th>\n",
       "      <th>SVM_TNR</th>\n",
       "      <th>SVM_FPR</th>\n",
       "      <th>SVM_FNR</th>\n",
       "      <th>SVM_TP</th>\n",
       "      <th>SVM_TN</th>\n",
       "      <th>SVM_FP</th>\n",
       "      <th>SVM_FN</th>\n",
       "      <th>...</th>\n",
       "      <th>DT_FP</th>\n",
       "      <th>DT_FN</th>\n",
       "      <th>ANN_TPR</th>\n",
       "      <th>ANN_TNR</th>\n",
       "      <th>ANN_FPR</th>\n",
       "      <th>ANN_FNR</th>\n",
       "      <th>ANN_TP</th>\n",
       "      <th>ANN_TN</th>\n",
       "      <th>ANN_FP</th>\n",
       "      <th>ANN_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.582938</td>\n",
       "      <td>0.998896</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.417062</td>\n",
       "      <td>123</td>\n",
       "      <td>2714</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>51</td>\n",
       "      <td>0.739336</td>\n",
       "      <td>0.997056</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.260664</td>\n",
       "      <td>156</td>\n",
       "      <td>2709</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.572052</td>\n",
       "      <td>0.999259</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.427948</td>\n",
       "      <td>131</td>\n",
       "      <td>2697</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>57</td>\n",
       "      <td>0.698690</td>\n",
       "      <td>0.998888</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.301310</td>\n",
       "      <td>160</td>\n",
       "      <td>2696</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.576190</td>\n",
       "      <td>0.998160</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.423810</td>\n",
       "      <td>121</td>\n",
       "      <td>2713</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>54</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.998896</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>140</td>\n",
       "      <td>2715</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.558685</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.441315</td>\n",
       "      <td>119</td>\n",
       "      <td>2714</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>144</td>\n",
       "      <td>2714</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.549107</td>\n",
       "      <td>0.999260</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.450893</td>\n",
       "      <td>123</td>\n",
       "      <td>2702</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>59</td>\n",
       "      <td>0.683036</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.316964</td>\n",
       "      <td>153</td>\n",
       "      <td>2700</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold   Group   SVM_TPR   SVM_TNR   SVM_FPR   SVM_FNR  SVM_TP  SVM_TN  \\\n",
       "0     1  Female  0.582938  0.998896  0.001104  0.417062     123    2714   \n",
       "1     2  Female  0.572052  0.999259  0.000741  0.427948     131    2697   \n",
       "2     3  Female  0.576190  0.998160  0.001840  0.423810     121    2713   \n",
       "3     4  Female  0.558685  0.999632  0.000368  0.441315     119    2714   \n",
       "4     5  Female  0.549107  0.999260  0.000740  0.450893     123    2702   \n",
       "\n",
       "   SVM_FP  SVM_FN  ...  DT_FP  DT_FN   ANN_TPR   ANN_TNR   ANN_FPR   ANN_FNR  \\\n",
       "0       3      88  ...     96     51  0.739336  0.997056  0.002944  0.260664   \n",
       "1       2      98  ...     70     57  0.698690  0.998888  0.001112  0.301310   \n",
       "2       5      89  ...     69     54  0.666667  0.998896  0.001104  0.333333   \n",
       "3       1      94  ...     59     56  0.676056  0.999632  0.000368  0.323944   \n",
       "4       2     101  ...     70     59  0.683036  0.998521  0.001479  0.316964   \n",
       "\n",
       "   ANN_TP  ANN_TN  ANN_FP  ANN_FN  \n",
       "0     156    2709       8      55  \n",
       "1     160    2696       3      69  \n",
       "2     140    2715       3      70  \n",
       "3     144    2714       1      69  \n",
       "4     153    2700       4      71  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a37b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def perform_t_tests(df, algorithm):\n",
    "    # Define the column names based on the algorithm\n",
    "    tpr_col = f\"{algorithm}_TPR\"\n",
    "    fpr_col = f\"{algorithm}_FPR\"\n",
    "    fn_col = f\"{algorithm}_FN\"\n",
    "    fp_col = f\"{algorithm}_FP\"\n",
    "    \n",
    "    # Define the groups\n",
    "    protected_group = df['Group'] == 'Female'\n",
    "    unprotected_group = ~protected_group\n",
    "\n",
    "    # Extract the metrics\n",
    "    protected_tpr = df.loc[protected_group, tpr_col].values\n",
    "    unprotected_tpr = df.loc[unprotected_group, tpr_col].values\n",
    "\n",
    "    protected_fpr = df.loc[protected_group, fpr_col].values\n",
    "    unprotected_fpr = df.loc[unprotected_group, fpr_col].values\n",
    "\n",
    "    protected_ratio_fn_fp = (df.loc[protected_group, fn_col] / df.loc[protected_group, fp_col]).values\n",
    "    unprotected_ratio_fn_fp = (df.loc[unprotected_group, fn_col] / df.loc[unprotected_group, fp_col]).values\n",
    "\n",
    "    # Perform t-tests\n",
    "\n",
    "    # Definition 1: Equalised Odds (TPR and FPR)\n",
    "    tpr_ttest = ttest_ind(protected_tpr, unprotected_tpr)\n",
    "    fpr_ttest = ttest_ind(protected_fpr, unprotected_fpr)\n",
    "\n",
    "    # Definition 2: Equal Opportunity (TPR)\n",
    "    equal_opportunity_ttest = ttest_ind(protected_tpr, unprotected_tpr)\n",
    "\n",
    "    # Definition 3: Treatment Equality (Ratio of false negatives to false positives)\n",
    "    treatment_equality_ttest = ttest_ind(protected_ratio_fn_fp, unprotected_ratio_fn_fp)\n",
    "\n",
    "    # Definition 4: Aggregate of all conditions\n",
    "    aggregate_tpr_ttest = ttest_ind(protected_tpr, unprotected_tpr)\n",
    "    aggregate_fpr_ttest = ttest_ind(protected_fpr, unprotected_fpr)\n",
    "    aggregate_ratio_ttest = ttest_ind(protected_ratio_fn_fp, unprotected_ratio_fn_fp)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"{algorithm} - Equalised Odds (TPR):\", tpr_ttest)\n",
    "    print(f\"{algorithm} - Equalised Odds (FPR):\", fpr_ttest)\n",
    "    print(f\"{algorithm} - Equal Opportunity (TPR):\", equal_opportunity_ttest)\n",
    "    print(f\"{algorithm} - Aggregate - TPR:\", aggregate_tpr_ttest)\n",
    "    print(f\"{algorithm} - Aggregate - FPR:\", aggregate_fpr_ttest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e19317bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Equalised Odds (TPR): TtestResult(statistic=-0.03732355519889093, pvalue=0.9704224143314983, df=38.0)\n",
      "SVM - Equalised Odds (FPR): TtestResult(statistic=-5.458773956237387, pvalue=3.1442561812078673e-06, df=38.0)\n",
      "SVM - Equal Opportunity (TPR): TtestResult(statistic=-0.03732355519889093, pvalue=0.9704224143314983, df=38.0)\n",
      "SVM - Aggregate - TPR: TtestResult(statistic=-0.03732355519889093, pvalue=0.9704224143314983, df=38.0)\n",
      "SVM - Aggregate - FPR: TtestResult(statistic=-5.458773956237387, pvalue=3.1442561812078673e-06, df=38.0)\n",
      "LR - Equalised Odds (TPR): TtestResult(statistic=-2.2105868887457527, pvalue=0.03315819725719151, df=38.0)\n",
      "LR - Equalised Odds (FPR): TtestResult(statistic=-5.241538262077401, pvalue=6.2291897026653475e-06, df=38.0)\n",
      "LR - Equal Opportunity (TPR): TtestResult(statistic=-2.2105868887457527, pvalue=0.03315819725719151, df=38.0)\n",
      "LR - Aggregate - TPR: TtestResult(statistic=-2.2105868887457527, pvalue=0.03315819725719151, df=38.0)\n",
      "LR - Aggregate - FPR: TtestResult(statistic=-5.241538262077401, pvalue=6.2291897026653475e-06, df=38.0)\n",
      "DT - Equalised Odds (TPR): TtestResult(statistic=-0.3231946474911426, pvalue=0.748319699125394, df=38.0)\n",
      "DT - Equalised Odds (FPR): TtestResult(statistic=-5.7364877173811095, pvalue=1.3088031368162245e-06, df=38.0)\n",
      "DT - Equal Opportunity (TPR): TtestResult(statistic=-0.3231946474911426, pvalue=0.748319699125394, df=38.0)\n",
      "DT - Aggregate - TPR: TtestResult(statistic=-0.3231946474911426, pvalue=0.748319699125394, df=38.0)\n",
      "DT - Aggregate - FPR: TtestResult(statistic=-5.7364877173811095, pvalue=1.3088031368162245e-06, df=38.0)\n",
      "RF - Equalised Odds (TPR): TtestResult(statistic=0.45451421643623613, pvalue=0.6520445943015812, df=38.0)\n",
      "RF - Equalised Odds (FPR): TtestResult(statistic=-2.6677707067667167, pvalue=0.01116078396017057, df=38.0)\n",
      "RF - Equal Opportunity (TPR): TtestResult(statistic=0.45451421643623613, pvalue=0.6520445943015812, df=38.0)\n",
      "RF - Aggregate - TPR: TtestResult(statistic=0.45451421643623613, pvalue=0.6520445943015812, df=38.0)\n",
      "RF - Aggregate - FPR: TtestResult(statistic=-2.6677707067667167, pvalue=0.01116078396017057, df=38.0)\n",
      "ANN - Equalised Odds (TPR): TtestResult(statistic=0.6897823018679813, pvalue=0.4945223111020203, df=38.0)\n",
      "ANN - Equalised Odds (FPR): TtestResult(statistic=-1.5648588587929257, pvalue=0.12590672038132017, df=38.0)\n",
      "ANN - Equal Opportunity (TPR): TtestResult(statistic=0.6897823018679813, pvalue=0.4945223111020203, df=38.0)\n",
      "ANN - Aggregate - TPR: TtestResult(statistic=0.6897823018679813, pvalue=0.4945223111020203, df=38.0)\n",
      "ANN - Aggregate - FPR: TtestResult(statistic=-1.5648588587929257, pvalue=0.12590672038132017, df=38.0)\n"
     ]
    }
   ],
   "source": [
    "perform_t_tests(df, 'SVM')\n",
    "perform_t_tests(df, 'LR')\n",
    "perform_t_tests(df, 'DT')\n",
    "perform_t_tests(df, 'RF')\n",
    "perform_t_tests(df, 'ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a1c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
